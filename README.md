# Spoofed Speech Attribution

This repository focuses on extending the functionality of the ['AASIST: Audio Anti-Spoofing using Integrated Spectro-Temporal Graph Attention Networks'](https://arxiv.org/abs/2110.01200)
 model to predict attributes that characterize spoofed speech. The approach introduces a bank of probabilistic detectors that are trained to identify specific features associated with selected spoofing techniques. This results in a comprehensive attribute-based representation of each audio sample. This representation is then analyzed using decision tree modeling to enable accurate spoofed speech detection and detailed explanations for the model's decisions. The dataset selected for the experiments is LA scenario of ASVSpoof 2019.

![full_arch](https://github.com/Manasi2001/Spoofed-Speech-Attribution/assets/68627617/1478fe33-27e8-4814-8c3e-09cceed162cf)

**Figure:** Complete implementation workflow of the proposed architecture for explainable spoofed speech detection. **Phase I** demonstrates the extraction of embeddings using the AASIST model and the subsequent processing of these embeddings through a bank of seven probabilistic feature detectors. **Phase II** illustrates the concatenation of the outputs from these detectors to create a 25-dimensional vector, which is then fed into a decision tree model for classification. This decision tree model is used for both bonafide/spoofed classification and spoofing attack algorithm characterization.

### Getting started

`requirements.txt` must be installed for execution. 

```
pip install -r requirements.txt
```

### Data preparation

To download the ASVspoof 2019 logical access dataset [2]:

```
python download_dataset.py
```

(Alternative) Manual preparation is available via: 
- ASVspoof2019 dataset: https://datashare.ed.ac.uk/handle/10283/3336
  1. Download `LA.zip` and unzip it.
  2. Set the dataset directory in the configuration file `config/AASIST.conf`.

## Phase I

### 1. Inference Embedding Extraction

The binary output layer of the AASIST model is stripped and the remaining architecture is used to produce 160-dimensional embeddings for all the audios in training, development and evaluation sets.

To extract AASIST embeddings:

```
python inference_embedding_extraction.py
```

A set of embeddings is available in `Embeddings/AASIST/` for further use. 

### 2. Designing Probabilistic Feature Detectors

The ASVSpoof 2019 dataset provides detailed metadata about the characteristics of each spoofing attack by organizing the spoofing methods into seven _attribute sets_: Input, Input Processor, Duration, Conversion, Speaker Representation, Output, and Waveform Generation. Probabilistic detectors are designed for each of these attribute sets such that they take the 160-dimensional "raw" AASIST embedding as their (shared) input, and are trained against ground truth labels to predict posterior probabilities for assessing the absence or presence of attributes associated with each spoofing attack algorithm.

To design a probabilistic feature detector for an attribute set:

```
python emb_main.py
```

The attribute set number, model architecture for probabilistic feature detector, and related parameters can be set in the configuration file `emb_model_AASIST.conf`. Experimentation shows that a two-layered neural network architecture with 64 and 32 neurons in the hidden layers, respectively, seems to outperform the other tested architectures with one hidden layer of 0, 4, 8, 32 or 64 neurons, and suits best for all the attribute sets. A set of trained probabilistic feature detectors is available in `probabilistic_detectors/` for further use.

## Phase II

### 1. Concatenation of Posterior Probabilities

All the audio recordings in the dataset are passed through the seven probabilistic feature detectors. The generated posterior probabilities are concatenated for each audio to form a 25-dimensional embeddings.

To calculate and concatenate the outputs generated by probabilistic feature detectors:

```
python create_df.py
```

The dataset (training/development/evaluation), the choice to apply `softmax` or `logit` functions to the probabilistic feature detectors' outputs and a common model architecture for all the detectors, can be set in the configuration file `emb_model_AASIST.conf`. A set of dataframes thus obtained, is available in `df_posterior_probabilities/` for further use.

### 2. Decision Tree Modelling

Decision tree models are designed for making use of these 25-dimensional embeddings for two tasks:

- Bonafide versus spoof classification:

```
python decision_tree.py --BonafideSpoof
```

- Spoofing attack algorithm attribution:

```
python3 decision_tree.py --SpoofAttacks
```

Results are stored in `decision_tree_results/`. Relative paths of the dataframes and the maximum depth of decision tree, can be set in the configuration file `emb_model_AASIST.conf`.

### License

```

```
